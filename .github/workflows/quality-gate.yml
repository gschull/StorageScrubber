name: Quality Gate

on:
  pull_request:
    branches: [ main, master, develop ]

permissions:
  contents: read
  pull-requests: write

jobs:
  python:
    name: Python Quality Gate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt', 'pyproject.toml', 'poetry.lock', 'requirements-*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f "requirements.txt" ]; then pip install -r requirements.txt; fi
          if [ -f "pyproject.toml" ]; then pip install -e .; fi
          pip install pytest mutmut pip-audit

      - name: Dependency health (pip-audit)
        run: |
          pip-audit -f json -o audit.json || true
          python - <<'PY'
          import json, sys
          try:
            with open('audit.json','r') as f:
              data = json.load(f)
            has_critical = False
            for item in data:
              for v in (item.get('vulns') or []):
                if (v.get('severity') or '').lower() == 'critical':
                  has_critical = True
                  break
            if has_critical:
              print("FAIL: Critical vulnerabilities found")
              sys.exit(1)
            print("PASS: No critical vulnerabilities")
          except Exception as e:
            print(f"Warning: Could not parse audit.json: {e}")
          PY

      - name: Run tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: pytest -q

      - name: Run mutation tests (mutmut)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: mutmut run || true

      - name: Collect Python metrics
        id: metrics
        run: |
          python - <<'PY'
          import json, os, sqlite3, sys
          out = {
            "ecosystem": "python",
            "mutation": {"score": None, "killed": 0, "survived": 0, "timeout": 0},
            "dependencies": {"critical": 0, "high": 0, "moderate": 0, "low": 0, "max_cvss": 0.0}
          }
          try:
            con = sqlite3.connect('.mutmut-cache')
            cur = con.cursor()
            counts = {s: 0 for s in ('killed','survived','timeout')}
            tables = {row[0] for row in cur.execute("SELECT name FROM sqlite_master WHERE type='table'")}
            status_col = 'status'
            table = None
            if 'results' in tables:
              table = 'results'
              # prefer 'status' but fall back to 'result' or 'outcome'
              cols = {r[1] for r in cur.execute("PRAGMA table_info(results)")}
              for c in ('status','result','outcome'):
                if c in cols:
                  status_col = c
                  break
            elif 'mutants' in tables:
              table = 'mutants'
              cols = {r[1] for r in cur.execute("PRAGMA table_info(mutants)")}
              for c in ('status','result','outcome'):
                if c in cols:
                  status_col = c
                  break
            # map mutmut statuses to killed/survived/timeout
            def map_status(s):
              try:
                k = (s or '').strip().lower()
              except Exception:
                k = str(s).strip().lower()
              if k in ('killed','ok','killed_by_test','detected'):
                return 'killed'
              if k in ('timeout','timed_out','killed_by_timeout'):
                return 'timeout'
              if k in ('survived','alive','suspicious','incompetent','no_result','uncertain'):
                return 'survived'
              if k in ('skipped','untested','ignored','hidden'):
                return None
              return 'survived'
            # Debug info to help map statuses correctly across mutmut versions
            try:
              print("Mutmut tables:", sorted(tables))
              print("Using:", table, status_col)
              if table:
                print("Distinct statuses:", [str(r[0]) for r in cur.execute(f"SELECT DISTINCT {status_col} FROM {table}")])
            except Exception:
              pass
            if table is not None:
              for status, cnt in cur.execute(f"SELECT {status_col}, COUNT(*) FROM {table} GROUP BY {status_col}"):
                m = map_status(status)
                if m in counts:
                  counts[m] += cnt
            killed, survived, timeout = counts['killed'], counts['survived'], counts['timeout']
            considered = killed + survived + timeout
            # Fallback: if DB has no useful tables, try parsing `mutmut results`
            if considered == 0:
              try:
                import subprocess, re
                res = subprocess.run(['mutmut','results'], capture_output=True, text=True, check=False)
                text = (res.stdout or '') + "\n" + (res.stderr or '')
                def get(pattern):
                  m = re.search(pattern, text, re.IGNORECASE)
                  return int(m.group(1)) if m else 0
                killed = get(r"Killed(?: mutants)?:\s*(\d+)")
                survived = get(r"Survived(?: mutants)?:\s*(\d+)")
                suspicious = get(r"Suspicious(?: mutants)?:\s*(\d+)")
                timeout = get(r"Timeouts?:\s*(\d+)")
                survived += suspicious
                considered = killed + survived + timeout
              except Exception:
                pass
            score = 100.0 if considered == 0 else (killed / considered) * 100.0
            out["mutation"]= {"score": round(score,2), "killed": killed, "survived": survived, "timeout": timeout}
          except Exception:
            pass
          finally:
            try:
              con.close()
            except Exception:
              pass
          try:
            with open('audit.json','r',encoding='utf-8') as f:
              data = json.load(f)
            max_cvss = 0.0
            sev = {"critical":0,"high":0,"moderate":0,"low":0}
            for item in data:
              vulns = item.get('vulns') or []
              for v in vulns:
                cvss = v.get('score','0')
                try:
                  cvss = float(cvss)
                except Exception:
                  cvss = 0.0
                max_cvss = max(max_cvss, cvss)
                s = (v.get('severity') or '').lower()
                if s in sev:
                  sev[s]+=1
            out["dependencies"]= {**sev, "max_cvss": max_cvss}
          except Exception:
            pass
          with open('python_metrics.json','w',encoding='utf-8') as f:
            json.dump(out,f)
          cur = con.cursor()
          counts = {s: 0 for s in ('killed','survived','timeout')}
          try:
            tables = {row[0] for row in cur.execute("SELECT name FROM sqlite_master WHERE type='table'")}
            status_col = 'status'
            table = None
            if 'results' in tables:
              table = 'results'
              cols = {r[1] for r in cur.execute("PRAGMA table_info(results)")}
              for c in ('status','result','outcome'):
                if c in cols:
                  status_col = c
                  break
            elif 'mutants' in tables:
              table = 'mutants'
              cols = {r[1] for r in cur.execute("PRAGMA table_info(mutants)")}
              for c in ('status','result','outcome'):
                if c in cols:
                  status_col = c
                  break
            def map_status(s):
              try:
                k = (s or '').strip().lower()
              except Exception:
                k = str(s).strip().lower()
              if k in ('killed','ok','killed_by_test','detected'):
                return 'killed'
              if k in ('timeout','timed_out','killed_by_timeout'):
                return 'timeout'
              if k in ('survived','alive','suspicious','incompetent','no_result','uncertain'):
                return 'survived'
              if k in ('skipped','untested','ignored','hidden'):
                return None
              return 'survived'
            # Try DB first if table present
            if table:
              try:
                print("Mutmut tables:", sorted(tables))
                print("Using:", table, status_col)
                print("Distinct statuses:", [str(r[0]) for r in cur.execute(f"SELECT DISTINCT {status_col} FROM {table}")])
              except Exception:
                pass
              for status, cnt in cur.execute(f"SELECT {status_col}, COUNT(*) FROM {table} GROUP BY {status_col}"):
                m = map_status(status)
                if m in counts:
                  counts[m] += cnt
          except Exception as e:
            print(f"Failed reading results from mutmut cache: {e}")
          finally:
            try:
              con.close()
            except Exception:
              pass
          killed = counts['killed']
          survived = counts['survived']
          timeout = counts['timeout']
          considered = killed + survived + timeout
          # Fallback: if DB has no useful tables, try parsing `mutmut results`
          if considered == 0:
            try:
              import subprocess, re
              res = subprocess.run(['mutmut','results'], capture_output=True, text=True, check=False)
              text = (res.stdout or '') + "\n" + (res.stderr or '')
              def get(pattern):
                m = re.search(pattern, text, re.IGNORECASE)
                return int(m.group(1)) if m else 0
              killed = get(r"Killed(?: mutants)?:\s*(\d+)")
              survived = get(r"Survived(?: mutants)?:\s*(\d+)")
              suspicious = get(r"Suspicious(?: mutants)?:\s*(\d+)")
              timeout = get(r"Timeouts?:\s*(\d+)")
              survived += suspicious
              considered = killed + survived + timeout
            except Exception as e:
              print(f"Fallback parse failed: {e}")
          score = 100.0 if considered == 0 else (killed / considered) * 100.0
          finally:
            try:
              con.close()
            except Exception:
              pass
          killed = counts['killed']
          survived = counts['survived']
          timeout = counts['timeout']
          considered = killed + survived + timeout
          score = 100.0 if considered == 0 else (killed / considered) * 100.0
          print(f"Mutation score: {score:.2f}% (killed={killed}, survived={survived}, timeout={timeout})")
          if score + 1e-9 < threshold:
            print(f"WARN: mutation score {score:.2f}% is below threshold {threshold:.2f}%")
          else:
            print("PASS: mutation score meets threshold")
          PY

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            function readJson(p) { try { return JSON.parse(fs.readFileSync(p,'utf8')); } catch { return null; } }
            const py = readJson('python_metrics.json');
            if (!py) {
              core.info('No metrics found, skipping comment');
              return;
            }
            const m = py.mutation || {};
            const d = py.dependencies || {};
            const body = [
              '## Quality Gate Summary',
              '',
              '| Metric | Value |',
              '|---|---:|',
              `| Mutation Score | ${m.score ?? 'â€“'}% |`,
              `| Mutations Killed | ${m.killed || 0} |`,
              `| Mutations Survived | ${m.survived || 0} |`,
              `| Vulnerabilities (C/H/M/L) | ${d.critical||0}/${d.high||0}/${d.moderate||0}/${d.low||0} |`,
              `| Max CVSS | ${d.max_cvss||0} |`,
              '',
              '_Higher mutation score = stronger tests. Critical vulns mean risky dependencies._'
            ].join('\n');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });

      - name: Upload metrics to dashboard
        env:
          UPLOAD_URL: ${{ secrets.QG_UPLOAD_URL }}
          UPLOAD_TOKEN: ${{ secrets.QUALITY_GATE_INGEST_TOKEN }}
        if: ${{ env.UPLOAD_URL != '' }}
        run: |
          python - <<'PY'
          import json, os, urllib.request
          with open('python_metrics.json','r') as f:
            metrics = json.load(f)
          payload = {
            "repository": os.environ.get('GITHUB_REPOSITORY'),
            "pr_number": os.environ.get('GITHUB_REF','').split('/')[-1],
            "commit_sha": os.environ.get('GITHUB_SHA'),
            "run_id": os.environ.get('GITHUB_RUN_ID'),
            "python": metrics,
            "generated_at": __import__('datetime').datetime.utcnow().isoformat() + 'Z'
          }
          url = os.environ.get('UPLOAD_URL', '')
          token = os.environ.get('UPLOAD_TOKEN', '')
          if not url or not token:
            print("Skipping upload: UPLOAD_URL or UPLOAD_TOKEN not set")
            exit(0)
          req = urllib.request.Request(
            url,
            data=json.dumps(payload).encode('utf-8'),
            headers={
              'Authorization': f'Bearer {token}',
              'Content-Type': 'application/json'
            }
          )
          try:
            with urllib.request.urlopen(req) as resp:
              print(f"Upload response: {resp.status}")
          except Exception as e:
            print(f"Upload failed: {e}")
          PY

