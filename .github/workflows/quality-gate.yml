name: Quality Gate

on:
  pull_request:
    branches: [ main, master, develop ]

permissions:
  contents: read
  pull-requests: write

jobs:
  python:
    name: Python Quality Gate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt', 'pyproject.toml', 'poetry.lock', 'requirements-*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f "requirements.txt" ]; then pip install -r requirements.txt; fi
          if [ -f "pyproject.toml" ]; then pip install -e .; fi
          pip install pytest mutmut pip-audit

      - name: Dependency health (pip-audit)
        run: |
          pip-audit -f json -o audit.json || true
          python - <<'PY'
          import json, sys
          try:
            with open('audit.json','r') as f:
              data = json.load(f)
            has_critical = False
            for item in data:
              for v in (item.get('vulns') or []):
                if (v.get('severity') or '').lower() == 'critical':
                  has_critical = True
                  break
            if has_critical:
              print("FAIL: Critical vulnerabilities found")
              sys.exit(1)
            print("PASS: No critical vulnerabilities")
          except Exception as e:
            print(f"Warning: Could not parse audit.json: {e}")
          PY

      - name: Run tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: pytest -q

      - name: Run mutation tests (mutmut)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: mutmut run || true

      - name: Collect Python metrics
        id: metrics
        run: |
          python - <<'PY'
          import json, sqlite3, subprocess, re, textwrap

          def read_mutation_counts():
              killed = survived = timeout = 0
              considered = 0
              source = "none"
              con = None
              try:
                  con = sqlite3.connect('.mutmut-cache')
                  cur = con.cursor()
                  tables = {row[0] for row in cur.execute("SELECT name FROM sqlite_master WHERE type='table'")}
                  table = 'results' if 'results' in tables else ('mutants' if 'mutants' in tables else None)
                  status_col = 'status'
                  if not table:
                      print(f"Mutmut DB tables: {sorted(tables)}")
                  if table:
                      cols = {r[1] for r in cur.execute(f"PRAGMA table_info({table})")}
                      print(f"Mutmut DB table '{table}' columns: {sorted(cols)}")
                      for c in ('status','result','outcome'):
                          if c in cols:
                              status_col = c
                              break
                      counts = {'killed':0,'survived':0,'timeout':0}
                      def map_status(s):
                          k = str(s or '').strip().lower()
                          if k in ('killed','ok','killed_by_test','detected'):
                              return 'killed'
                          if k in ('timeout','timed_out','killed_by_timeout'):
                              return 'timeout'
                          if k in ('survived','alive','suspicious','incompetent','no_result','uncertain'):
                              return 'survived'
                          if k in ('skipped','untested','ignored','hidden'):
                              return None
                          return 'survived'
                      for status, cnt in cur.execute(f"SELECT {status_col}, COUNT(*) FROM {table} GROUP BY {status_col}"):
                          m = map_status(status)
                          if m in counts:
                              counts[m] += int(cnt)
                      killed, survived, timeout = counts['killed'], counts['survived'], counts['timeout']
                      considered = killed + survived + timeout
                      source = "db"
              except Exception as e:
                  print(f"Mutmut DB read error: {e}")
              finally:
                  try:
                      con and con.close()
                  except Exception:
                      pass

              if considered == 0:
                  try:
                      res = subprocess.run(['mutmut','results'], capture_output=True, text=True, check=False)
                      text = (res.stdout or '') + '\n' + (res.stderr or '')
                      # Print a trimmed version of the output for debugging/format discovery
                      trimmed = '\n'.join(text.splitlines()[:50])
                      print("mutmut results (first lines):\n" + textwrap.indent(trimmed, prefix="  "))

                      # Try multiple parsing strategies
                      def get_first(pat):
                          m = re.search(pat, text, re.IGNORECASE | re.MULTILINE)
                          return int(m.group(1)) if m else 0

                      killed = get_first(r"^\s*Killed(?:\s+mutants)?\s*:\s*(\d+)") or get_first(r"killed\s+(\d+)")
                      survived_only = get_first(r"^\s*Survived(?:\s+mutants)?\s*:\s*(\d+)") or get_first(r"survived\s+(\d+)")
                      suspicious = get_first(r"^\s*Suspicious(?:\s+mutants)?\s*:\s*(\d+)") or get_first(r"suspicious\s+(\d+)")
                      timeout = get_first(r"^\s*Timeouts?\s*:\s*(\d+)") or get_first(r"timed\s*out\s*:\s*(\d+)") or get_first(r"timeout\s+(\d+)")

                      survived = survived_only + suspicious
                      considered = killed + survived + timeout
                      source = "cli"
                  except Exception as e:
                      print(f"Mutmut CLI parse error: {e}")
              return killed, survived, timeout, considered, source

          def read_dep_metrics():
              try:
                  with open('audit.json','r',encoding='utf-8') as f:
                      data = json.load(f)
                  # Some environments produce a JSON string like "No known vulnerabilities found".
                  if isinstance(data, str):
                      return {"critical":0,"high":0,"moderate":0,"low":0,"max_cvss":0.0}
                  sev = {'critical':0,'high':0,'moderate':0,'low':0}
                  max_cvss = 0.0
                  for item in data:
                      for v in (item.get('vulns') or []):
                          s = (v.get('severity') or '').lower()
                          if s in sev:
                              sev[s] += 1
                          try:
                              score = float(v.get('score','0') or 0)
                          except Exception:
                              score = 0.0
                          if score > max_cvss:
                              max_cvss = score
                  return {**sev, 'max_cvss': max_cvss}
              except Exception as e:
                  print(f"Dependency parse warning: {e}")
                  return {"critical":0,"high":0,"moderate":0,"low":0,"max_cvss":0.0}

          killed, survived, timeout, considered, source = read_mutation_counts()
          score = 100.0 if considered == 0 else round((killed / max(1, considered)) * 100.0, 2)
          deps = read_dep_metrics()
          out = {
              "ecosystem": "python",
              "mutation": {"score": score, "killed": killed, "survived": survived, "timeout": timeout, "source": source},
              "dependencies": deps,
          }
          with open('python_metrics.json','w',encoding='utf-8') as f:
              json.dump(out,f)
          print(f"Mutation score: {score:.2f}% via {source} (killed={killed}, survived={survived}, timeout={timeout})")
          PY

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            function readJson(p) { try { return JSON.parse(fs.readFileSync(p,'utf8')); } catch { return null; } }
            const py = readJson('python_metrics.json');
            if (!py) {
              core.info('No metrics found, skipping comment');
              return;
            }
            const m = py.mutation || {};
            const d = py.dependencies || {};
            const body = [
              '## Quality Gate Summary',
              '',
              '| Metric | Value |',
              '|---|---:|',
              `| Mutation Score | ${m.score ?? 'â€“'}% |`,
              `| Mutations Killed | ${m.killed || 0} |`,
              `| Mutations Survived | ${m.survived || 0} |`,
              `| Vulnerabilities (C/H/M/L) | ${d.critical||0}/${d.high||0}/${d.moderate||0}/${d.low||0} |`,
              `| Max CVSS | ${d.max_cvss||0} |`,
              '',
              '_Higher mutation score = stronger tests. Critical vulns mean risky dependencies._'
            ].join('\n');
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body
            });

      - name: Upload metrics to dashboard
        env:
          UPLOAD_URL: ${{ secrets.QG_UPLOAD_URL }}
          UPLOAD_TOKEN: ${{ secrets.QUALITY_GATE_INGEST_TOKEN }}
        if: ${{ env.UPLOAD_URL != '' }}
        run: |
          python - <<'PY'
          import json, os, urllib.request
          with open('python_metrics.json','r') as f:
            metrics = json.load(f)
          payload = {
            "repository": os.environ.get('GITHUB_REPOSITORY'),
            "pr_number": os.environ.get('GITHUB_REF','').split('/')[-1],
            "commit_sha": os.environ.get('GITHUB_SHA'),
            "run_id": os.environ.get('GITHUB_RUN_ID'),
            "python": metrics,
            "generated_at": __import__('datetime').datetime.utcnow().isoformat() + 'Z'
          }
          url = os.environ.get('UPLOAD_URL', '')
          token = os.environ.get('UPLOAD_TOKEN', '')
          if not url or not token:
            print("Skipping upload: UPLOAD_URL or UPLOAD_TOKEN not set")
            exit(0)
          req = urllib.request.Request(
            url,
            data=json.dumps(payload).encode('utf-8'),
            headers={
              'Authorization': f'Bearer {token}',
              'Content-Type': 'application/json'
            }
          )
          try:
            with urllib.request.urlopen(req) as resp:
              print(f"Upload response: {resp.status}")
          except Exception as e:
            print(f"Upload failed: {e}")
          PY

